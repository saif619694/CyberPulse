# ğŸ›¡ï¸ CyberPulse - Security Funding Intelligence

A comprehensive Python application for tracking and analyzing cybersecurity funding data in real-time. Built with Flask backend and Streamlit frontend, providing professional-grade market intelligence.

## âœ¨ Features

### ğŸ” Data Collection & Management
- **Automated web scraping** from security funding sources
- **Real-time data collection** with configurable scheduling
- **MongoDB integration** for robust data storage
- **Duplicate detection** and data validation

### ğŸ“Š Advanced Analytics
- **Interactive data visualization** with Plotly charts
- **Multiple view modes**: Cards, Table, and Chart views
- **Advanced search & filtering** capabilities
- **Real-time statistics** and market insights

### ğŸ¨ Modern User Interface
- **Professional Streamlit frontend** with cyberpunk-inspired design
- **Responsive layout** optimized for desktop and mobile
- **Dark theme** with customizable preferences
- **Intuitive navigation** and user experience

### âš¡ High Performance
- **Asynchronous processing** for data collection
- **Efficient pagination** for large datasets
- **Caching mechanisms** for improved performance
- **Background scheduling** for automated updates

## ğŸ—ï¸ Architecture

```
security-funded-python/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/          # Flask API & Data Processing
â”‚   â”‚   â”œâ”€â”€ main.py       # Flask application
â”‚   â”‚   â”œâ”€â”€ security_funded.py  # Web scraping logic
â”‚   â”‚   â”œâ”€â”€ models.py     # Data models
â”‚   â”‚   â””â”€â”€ database.py   # MongoDB interface
â”‚   â”œâ”€â”€ frontend/         # Streamlit Application
â”‚   â”‚   â”œâ”€â”€ streamlit_app.py    # Main Streamlit app
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â””â”€â”€ utils/        # Utilities & API client
â”‚   â””â”€â”€ shared/           # Shared configuration
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ docker-compose.yml    # Multi-service setup
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- MongoDB Atlas account or local MongoDB
- Docker & Docker Compose (optional)

### 1. Clone Repository

```bash
git clone <repository-url>
cd security-funded-python
```

### 2. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your MongoDB credentials
nano .env
```

### 3. Install Dependencies

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install requirements
pip install -r requirements.txt
```

### 4. Run Application

#### Option A: Using Startup Script
```bash
chmod +x start.sh
./start.sh
```

#### Option B: Manual Start
```bash
# Terminal 1 - Start Flask API
python -m app.backend.main

# Terminal 2 - Start Streamlit Frontend
streamlit run app/frontend/streamlit_app.py
```

#### Option C: Using Docker
```bash
# Build and run with Docker Compose
docker-compose up --build
```

### 5. Access Application

- **Frontend**: http://localhost:8501
- **API**: http://localhost:8000
- **Health Check**: http://localhost:8000/api/health

## ğŸ“‹ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DB_USERNAME` | MongoDB username | Required |
| `DB_PASSWORD` | MongoDB password | Required |
| `FLASK_HOST` | Flask server host | 127.0.0.1 |
| `FLASK_PORT` | Flask server port | 8000 |
| `STREAMLIT_HOST` | Streamlit host | 127.0.0.1 |
| `STREAMLIT_PORT` | Streamlit port | 8501 |
| `API_BASE_URL` | API base URL | http://127.0.0.1:8000 |
| `DEFAULT_PAGE_SIZE` | Default pagination size | 12 |
| `SCHEDULER_INTERVAL_HOURS` | Data collection interval | 4 |

## ğŸ”§ API Endpoints

### Data Endpoints
- `GET /api/funding-data` - Get paginated funding data
- `GET /api/funding-rounds` - Get available funding rounds
- `GET /api/stats` - Get database statistics

### Management Endpoints
- `GET /api/get_data` - Trigger data collection
- `GET /api/health` - Health check

### Query Parameters
- `page` - Page number (default: 1)
- `itemsPerPage` - Items per page (default: 12)
- `sortField` - Sort field (date, company_name, amount)
- `sortDirection` - Sort direction (asc, desc)
- `search` - Search term
- `filterRound` - Filter by funding round

## ğŸ“Š Data Sources

The application currently scrapes data from:
- **Return on Security** - Primary cybersecurity funding source
- **Public funding announcements**
- **Venture capital databases**

### Data Fields
- Company name and URL
- Funding amount and round
- Investor information
- Company type (Product/Service)
- Funding date
- Source links

## ğŸ› ï¸ Development

### Project Structure

```
app/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # Flask API server
â”‚   â”œâ”€â”€ security_funded.py   # Web scraping engine
â”‚   â”œâ”€â”€ models.py            # Data models & validation
â”‚   â””â”€â”€ database.py          # MongoDB operations
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ streamlit_app.py     # Main Streamlit application
â”‚   â”œâ”€â”€ components/          # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ header.py        # Header & branding
â”‚   â”‚   â”œâ”€â”€ search_bar.py    # Search & filters
â”‚   â”‚   â”œâ”€â”€ data_display.py  # Data visualization
â”‚   â”‚   â””â”€â”€ sidebar.py       # Navigation & settings
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ api_client.py    # API communication
â”‚       â””â”€â”€ formatters.py    # Data formatting utilities
â””â”€â”€ shared/
    â””â”€â”€ config.py            # Shared configuration
```

### Adding New Features

1. **Backend**: Add new endpoints in `app/backend/main.py`
2. **Frontend**: Create components in `app/frontend/components/`
3. **Data Models**: Extend models in `app/backend/models.py`
4. **Styling**: Update CSS in `app/frontend/streamlit_app.py`

### Testing

```bash
# Run API tests
python -m pytest tests/test_api.py

# Run scraping tests
python -m pytest tests/test_scraping.py

# Manual testing
python -m app.backend.security_funded
```

## ğŸ“¦ Deployment

### Docker Deployment

```bash
# Build image
docker build -t cyberpulse .

# Run container
docker run -p 8000:8000 -p 8501:8501 --env-file .env cyberpulse
```

### Production Deployment

1. **Set environment variables** for production
2. **Configure MongoDB** connection string
3. **Set up reverse proxy** (Nginx) if needed
4. **Enable HTTPS** for security
5. **Configure monitoring** and logging

### Docker Compose Production

```bash
# Run with production profile
docker-compose --profile production up -d
```

## ğŸ”’ Security Considerations

- **Environment Variables**: Never commit `.env` files
- **MongoDB**: Use strong credentials and connection encryption
- **Rate Limiting**: Implement rate limiting for API endpoints
- **CORS**: Configure CORS properly for production
- **HTTPS**: Use HTTPS in production environments

## ğŸ“ˆ Performance Optimization

- **Database Indexing**: Optimize MongoDB queries with proper indexes
- **Caching**: Implement Redis caching for frequently accessed data
- **Lazy Loading**: Use pagination and lazy loading for large datasets
- **Background Processing**: Use Celery for heavy data processing tasks

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Issues**: Report bugs and request features via GitHub Issues
- **Documentation**: Check the wiki for detailed documentation
- **Discord**: Join our community Discord server

## ğŸ™ Acknowledgments

- **Return on Security** for providing funding data
- **Streamlit** for the amazing frontend framework
- **Flask** for the robust backend framework
- **MongoDB** for reliable data storage

---

**Built with â¤ï¸ by the CyberPulse Team**

ğŸ›¡ï¸ *Tracking the pulse of cybersecurity innovation*